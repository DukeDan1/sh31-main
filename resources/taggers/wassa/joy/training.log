2023-11-17 23:16:04,271 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,271 Model: "TextRegressor(
  (document_embeddings): TransformerDocumentEmbeddings(
    (model): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30523, 768)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0-5): 6 x TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
              (activation): GELUActivation()
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
  )
  (decoder): Linear(in_features=768, out_features=1, bias=True)
  (loss_function): MSELoss()
)"
2023-11-17 23:16:04,271 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 Corpus: 822 train + 78 dev + 713 test sentences
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 Train:  822 sentences
2023-11-17 23:16:04,272         (train_with_dev=False, train_with_test=False)
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 Training Params:
2023-11-17 23:16:04,272  - learning_rate: "5e-05" 
2023-11-17 23:16:04,272  - mini_batch_size: "4"
2023-11-17 23:16:04,272  - max_epochs: "10"
2023-11-17 23:16:04,272  - shuffle: "True"
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 Plugins:
2023-11-17 23:16:04,272  - LinearScheduler | warmup_fraction: '0.1'
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 Final evaluation on model after last epoch (final-model.pt)
2023-11-17 23:16:04,272  - metric: "('micro avg', 'f1-score')"
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 Computation:
2023-11-17 23:16:04,272  - compute on device: cuda:0
2023-11-17 23:16:04,272  - embedding storage: none
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 Model training base path: "resources/taggers/wassa/joy"
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:04,272 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:05,659 epoch 1 - iter 20/206 - loss 0.14858992 - time (sec): 1.39 - samples/sec: 57.67 - lr: 0.000005 - momentum: 0.000000
2023-11-17 23:16:06,252 epoch 1 - iter 40/206 - loss 0.12737645 - time (sec): 1.98 - samples/sec: 80.81 - lr: 0.000009 - momentum: 0.000000
2023-11-17 23:16:06,832 epoch 1 - iter 60/206 - loss 0.11353698 - time (sec): 2.56 - samples/sec: 93.74 - lr: 0.000014 - momentum: 0.000000
2023-11-17 23:16:07,415 epoch 1 - iter 80/206 - loss 0.10871490 - time (sec): 3.14 - samples/sec: 101.83 - lr: 0.000019 - momentum: 0.000000
2023-11-17 23:16:08,001 epoch 1 - iter 100/206 - loss 0.09886539 - time (sec): 3.73 - samples/sec: 107.26 - lr: 0.000024 - momentum: 0.000000
2023-11-17 23:16:08,580 epoch 1 - iter 120/206 - loss 0.09081754 - time (sec): 4.31 - samples/sec: 111.43 - lr: 0.000029 - momentum: 0.000000
2023-11-17 23:16:09,163 epoch 1 - iter 140/206 - loss 0.09162926 - time (sec): 4.89 - samples/sec: 114.50 - lr: 0.000034 - momentum: 0.000000
2023-11-17 23:16:09,747 epoch 1 - iter 160/206 - loss 0.08572857 - time (sec): 5.48 - samples/sec: 116.89 - lr: 0.000039 - momentum: 0.000000
2023-11-17 23:16:10,350 epoch 1 - iter 180/206 - loss 0.08054730 - time (sec): 6.08 - samples/sec: 118.47 - lr: 0.000043 - momentum: 0.000000
2023-11-17 23:16:10,933 epoch 1 - iter 200/206 - loss 0.07546138 - time (sec): 6.66 - samples/sec: 120.10 - lr: 0.000048 - momentum: 0.000000
2023-11-17 23:16:11,109 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:11,109 EPOCH 1 done: loss 0.0741 - lr: 0.000048
2023-11-17 23:16:11,198 DEV : loss 0.04507989063858986 - f1-score (micro avg)  0.7032
2023-11-17 23:16:11,211 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:11,784 epoch 2 - iter 20/206 - loss 0.07007107 - time (sec): 0.57 - samples/sec: 139.73 - lr: 0.000049 - momentum: 0.000000
2023-11-17 23:16:12,373 epoch 2 - iter 40/206 - loss 0.06522047 - time (sec): 1.16 - samples/sec: 137.76 - lr: 0.000049 - momentum: 0.000000
2023-11-17 23:16:12,954 epoch 2 - iter 60/206 - loss 0.05449184 - time (sec): 1.74 - samples/sec: 137.72 - lr: 0.000048 - momentum: 0.000000
2023-11-17 23:16:13,552 epoch 2 - iter 80/206 - loss 0.04818824 - time (sec): 2.34 - samples/sec: 136.74 - lr: 0.000048 - momentum: 0.000000
2023-11-17 23:16:14,140 epoch 2 - iter 100/206 - loss 0.04439330 - time (sec): 2.93 - samples/sec: 136.61 - lr: 0.000047 - momentum: 0.000000
2023-11-17 23:16:14,722 epoch 2 - iter 120/206 - loss 0.04479767 - time (sec): 3.51 - samples/sec: 136.75 - lr: 0.000047 - momentum: 0.000000
2023-11-17 23:16:15,307 epoch 2 - iter 140/206 - loss 0.04163640 - time (sec): 4.10 - samples/sec: 136.72 - lr: 0.000046 - momentum: 0.000000
2023-11-17 23:16:15,891 epoch 2 - iter 160/206 - loss 0.03960559 - time (sec): 4.68 - samples/sec: 136.77 - lr: 0.000046 - momentum: 0.000000
2023-11-17 23:16:16,489 epoch 2 - iter 180/206 - loss 0.03783201 - time (sec): 5.28 - samples/sec: 136.44 - lr: 0.000045 - momentum: 0.000000
2023-11-17 23:16:17,077 epoch 2 - iter 200/206 - loss 0.03642474 - time (sec): 5.87 - samples/sec: 136.39 - lr: 0.000045 - momentum: 0.000000
2023-11-17 23:16:17,254 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:17,254 EPOCH 2 done: loss 0.0362 - lr: 0.000045
2023-11-17 23:16:17,347 DEV : loss 0.02670096792280674 - f1-score (micro avg)  0.7252
2023-11-17 23:16:17,360 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:17,931 epoch 3 - iter 20/206 - loss 0.02224604 - time (sec): 0.57 - samples/sec: 140.29 - lr: 0.000044 - momentum: 0.000000
2023-11-17 23:16:18,528 epoch 3 - iter 40/206 - loss 0.02083569 - time (sec): 1.17 - samples/sec: 137.02 - lr: 0.000043 - momentum: 0.000000
2023-11-17 23:16:19,122 epoch 3 - iter 60/206 - loss 0.02076869 - time (sec): 1.76 - samples/sec: 136.22 - lr: 0.000043 - momentum: 0.000000
2023-11-17 23:16:19,719 epoch 3 - iter 80/206 - loss 0.02425269 - time (sec): 2.36 - samples/sec: 135.70 - lr: 0.000042 - momentum: 0.000000
2023-11-17 23:16:20,310 epoch 3 - iter 100/206 - loss 0.02391881 - time (sec): 2.95 - samples/sec: 135.64 - lr: 0.000042 - momentum: 0.000000
2023-11-17 23:16:20,896 epoch 3 - iter 120/206 - loss 0.02340834 - time (sec): 3.54 - samples/sec: 135.77 - lr: 0.000041 - momentum: 0.000000
2023-11-17 23:16:21,479 epoch 3 - iter 140/206 - loss 0.02203692 - time (sec): 4.12 - samples/sec: 135.99 - lr: 0.000041 - momentum: 0.000000
2023-11-17 23:16:22,076 epoch 3 - iter 160/206 - loss 0.02215980 - time (sec): 4.72 - samples/sec: 135.73 - lr: 0.000040 - momentum: 0.000000
2023-11-17 23:16:22,672 epoch 3 - iter 180/206 - loss 0.02228256 - time (sec): 5.31 - samples/sec: 135.56 - lr: 0.000040 - momentum: 0.000000
2023-11-17 23:16:23,262 epoch 3 - iter 200/206 - loss 0.02184825 - time (sec): 5.90 - samples/sec: 135.56 - lr: 0.000039 - momentum: 0.000000
2023-11-17 23:16:23,441 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:23,441 EPOCH 3 done: loss 0.0216 - lr: 0.000039
2023-11-17 23:16:23,541 DEV : loss 0.026282204315066338 - f1-score (micro avg)  0.8116
2023-11-17 23:16:23,555 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:24,127 epoch 4 - iter 20/206 - loss 0.01903468 - time (sec): 0.57 - samples/sec: 140.08 - lr: 0.000038 - momentum: 0.000000
2023-11-17 23:16:24,740 epoch 4 - iter 40/206 - loss 0.01715162 - time (sec): 1.18 - samples/sec: 135.04 - lr: 0.000038 - momentum: 0.000000
2023-11-17 23:16:25,333 epoch 4 - iter 60/206 - loss 0.01861180 - time (sec): 1.78 - samples/sec: 134.99 - lr: 0.000037 - momentum: 0.000000
2023-11-17 23:16:25,923 epoch 4 - iter 80/206 - loss 0.01773443 - time (sec): 2.37 - samples/sec: 135.15 - lr: 0.000037 - momentum: 0.000000
2023-11-17 23:16:26,525 epoch 4 - iter 100/206 - loss 0.01654488 - time (sec): 2.97 - samples/sec: 134.72 - lr: 0.000036 - momentum: 0.000000
2023-11-17 23:16:27,106 epoch 4 - iter 120/206 - loss 0.01614233 - time (sec): 3.55 - samples/sec: 135.18 - lr: 0.000036 - momentum: 0.000000
2023-11-17 23:16:27,695 epoch 4 - iter 140/206 - loss 0.01687232 - time (sec): 4.14 - samples/sec: 135.28 - lr: 0.000035 - momentum: 0.000000
2023-11-17 23:16:28,287 epoch 4 - iter 160/206 - loss 0.01624841 - time (sec): 4.73 - samples/sec: 135.27 - lr: 0.000035 - momentum: 0.000000
2023-11-17 23:16:28,879 epoch 4 - iter 180/206 - loss 0.01534040 - time (sec): 5.32 - samples/sec: 135.26 - lr: 0.000034 - momentum: 0.000000
2023-11-17 23:16:29,475 epoch 4 - iter 200/206 - loss 0.01518793 - time (sec): 5.92 - samples/sec: 135.15 - lr: 0.000034 - momentum: 0.000000
2023-11-17 23:16:29,653 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:29,653 EPOCH 4 done: loss 0.0151 - lr: 0.000034
2023-11-17 23:16:29,747 DEV : loss 0.019053857773542404 - f1-score (micro avg)  0.7877
2023-11-17 23:16:29,762 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:30,339 epoch 5 - iter 20/206 - loss 0.00701915 - time (sec): 0.58 - samples/sec: 138.75 - lr: 0.000033 - momentum: 0.000000
2023-11-17 23:16:30,931 epoch 5 - iter 40/206 - loss 0.00749700 - time (sec): 1.17 - samples/sec: 136.90 - lr: 0.000032 - momentum: 0.000000
2023-11-17 23:16:31,520 epoch 5 - iter 60/206 - loss 0.00899018 - time (sec): 1.76 - samples/sec: 136.56 - lr: 0.000032 - momentum: 0.000000
2023-11-17 23:16:32,118 epoch 5 - iter 80/206 - loss 0.00990588 - time (sec): 2.36 - samples/sec: 135.86 - lr: 0.000031 - momentum: 0.000000
2023-11-17 23:16:32,722 epoch 5 - iter 100/206 - loss 0.00934826 - time (sec): 2.96 - samples/sec: 135.16 - lr: 0.000031 - momentum: 0.000000
2023-11-17 23:16:33,306 epoch 5 - iter 120/206 - loss 0.00899369 - time (sec): 3.54 - samples/sec: 135.46 - lr: 0.000030 - momentum: 0.000000
2023-11-17 23:16:33,900 epoch 5 - iter 140/206 - loss 0.00871042 - time (sec): 4.14 - samples/sec: 135.34 - lr: 0.000030 - momentum: 0.000000
2023-11-17 23:16:34,489 epoch 5 - iter 160/206 - loss 0.00854873 - time (sec): 4.73 - samples/sec: 135.41 - lr: 0.000029 - momentum: 0.000000
2023-11-17 23:16:35,086 epoch 5 - iter 180/206 - loss 0.00844262 - time (sec): 5.32 - samples/sec: 135.25 - lr: 0.000029 - momentum: 0.000000
2023-11-17 23:16:35,685 epoch 5 - iter 200/206 - loss 0.00838037 - time (sec): 5.92 - samples/sec: 135.07 - lr: 0.000028 - momentum: 0.000000
2023-11-17 23:16:35,862 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:35,862 EPOCH 5 done: loss 0.0084 - lr: 0.000028
2023-11-17 23:16:35,958 DEV : loss 0.014845006167888641 - f1-score (micro avg)  0.8312
2023-11-17 23:16:35,972 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:36,576 epoch 6 - iter 20/206 - loss 0.00600065 - time (sec): 0.60 - samples/sec: 132.55 - lr: 0.000027 - momentum: 0.000000
2023-11-17 23:16:37,187 epoch 6 - iter 40/206 - loss 0.00771753 - time (sec): 1.21 - samples/sec: 131.79 - lr: 0.000027 - momentum: 0.000000
2023-11-17 23:16:38,030 epoch 6 - iter 60/206 - loss 0.00706096 - time (sec): 2.06 - samples/sec: 116.68 - lr: 0.000026 - momentum: 0.000000
2023-11-17 23:16:38,883 epoch 6 - iter 80/206 - loss 0.00713247 - time (sec): 2.91 - samples/sec: 109.94 - lr: 0.000026 - momentum: 0.000000
2023-11-17 23:16:39,722 epoch 6 - iter 100/206 - loss 0.00678723 - time (sec): 3.75 - samples/sec: 106.69 - lr: 0.000025 - momentum: 0.000000
2023-11-17 23:16:40,583 epoch 6 - iter 120/206 - loss 0.00625678 - time (sec): 4.61 - samples/sec: 104.11 - lr: 0.000025 - momentum: 0.000000
2023-11-17 23:16:41,462 epoch 6 - iter 140/206 - loss 0.00617988 - time (sec): 5.49 - samples/sec: 102.01 - lr: 0.000024 - momentum: 0.000000
2023-11-17 23:16:42,331 epoch 6 - iter 160/206 - loss 0.00598838 - time (sec): 6.36 - samples/sec: 100.66 - lr: 0.000024 - momentum: 0.000000
2023-11-17 23:16:43,182 epoch 6 - iter 180/206 - loss 0.00576983 - time (sec): 7.21 - samples/sec: 99.87 - lr: 0.000023 - momentum: 0.000000
2023-11-17 23:16:44,028 epoch 6 - iter 200/206 - loss 0.00575555 - time (sec): 8.06 - samples/sec: 99.31 - lr: 0.000022 - momentum: 0.000000
2023-11-17 23:16:44,274 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:44,275 EPOCH 6 done: loss 0.0057 - lr: 0.000022
2023-11-17 23:16:44,421 DEV : loss 0.019816599786281586 - f1-score (micro avg)  0.8192
2023-11-17 23:16:44,436 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:45,239 epoch 7 - iter 20/206 - loss 0.00736830 - time (sec): 0.80 - samples/sec: 99.70 - lr: 0.000022 - momentum: 0.000000
2023-11-17 23:16:46,063 epoch 7 - iter 40/206 - loss 0.00671437 - time (sec): 1.63 - samples/sec: 98.41 - lr: 0.000021 - momentum: 0.000000
2023-11-17 23:16:46,921 epoch 7 - iter 60/206 - loss 0.00576561 - time (sec): 2.48 - samples/sec: 96.61 - lr: 0.000021 - momentum: 0.000000
2023-11-17 23:16:47,761 epoch 7 - iter 80/206 - loss 0.00555301 - time (sec): 3.32 - samples/sec: 96.26 - lr: 0.000020 - momentum: 0.000000
2023-11-17 23:16:48,569 epoch 7 - iter 100/206 - loss 0.00507452 - time (sec): 4.13 - samples/sec: 96.81 - lr: 0.000020 - momentum: 0.000000
2023-11-17 23:16:49,396 epoch 7 - iter 120/206 - loss 0.00508937 - time (sec): 4.96 - samples/sec: 96.79 - lr: 0.000019 - momentum: 0.000000
2023-11-17 23:16:50,232 epoch 7 - iter 140/206 - loss 0.00483364 - time (sec): 5.79 - samples/sec: 96.64 - lr: 0.000019 - momentum: 0.000000
2023-11-17 23:16:51,080 epoch 7 - iter 160/206 - loss 0.00463339 - time (sec): 6.64 - samples/sec: 96.34 - lr: 0.000018 - momentum: 0.000000
2023-11-17 23:16:51,924 epoch 7 - iter 180/206 - loss 0.00464235 - time (sec): 7.49 - samples/sec: 96.16 - lr: 0.000017 - momentum: 0.000000
2023-11-17 23:16:52,744 epoch 7 - iter 200/206 - loss 0.00448783 - time (sec): 8.31 - samples/sec: 96.30 - lr: 0.000017 - momentum: 0.000000
2023-11-17 23:16:52,996 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:52,996 EPOCH 7 done: loss 0.0045 - lr: 0.000017
2023-11-17 23:16:53,135 DEV : loss 0.018348608165979385 - f1-score (micro avg)  0.8252
2023-11-17 23:16:53,150 ----------------------------------------------------------------------------------------------------
2023-11-17 23:16:53,959 epoch 8 - iter 20/206 - loss 0.00376124 - time (sec): 0.81 - samples/sec: 98.94 - lr: 0.000016 - momentum: 0.000000
2023-11-17 23:16:54,776 epoch 8 - iter 40/206 - loss 0.00403542 - time (sec): 1.63 - samples/sec: 98.41 - lr: 0.000016 - momentum: 0.000000
2023-11-17 23:16:55,604 epoch 8 - iter 60/206 - loss 0.00359819 - time (sec): 2.45 - samples/sec: 97.84 - lr: 0.000015 - momentum: 0.000000
2023-11-17 23:16:56,437 epoch 8 - iter 80/206 - loss 0.00362081 - time (sec): 3.29 - samples/sec: 97.36 - lr: 0.000015 - momentum: 0.000000
2023-11-17 23:16:57,264 epoch 8 - iter 100/206 - loss 0.00365532 - time (sec): 4.11 - samples/sec: 97.24 - lr: 0.000014 - momentum: 0.000000
2023-11-17 23:16:58,092 epoch 8 - iter 120/206 - loss 0.00357785 - time (sec): 4.94 - samples/sec: 97.14 - lr: 0.000013 - momentum: 0.000000
2023-11-17 23:16:58,932 epoch 8 - iter 140/206 - loss 0.00351478 - time (sec): 5.78 - samples/sec: 96.87 - lr: 0.000013 - momentum: 0.000000
2023-11-17 23:16:59,763 epoch 8 - iter 160/206 - loss 0.00334419 - time (sec): 6.61 - samples/sec: 96.78 - lr: 0.000012 - momentum: 0.000000
2023-11-17 23:17:00,616 epoch 8 - iter 180/206 - loss 0.00316876 - time (sec): 7.47 - samples/sec: 96.45 - lr: 0.000012 - momentum: 0.000000
2023-11-17 23:17:01,461 epoch 8 - iter 200/206 - loss 0.00311986 - time (sec): 8.31 - samples/sec: 96.27 - lr: 0.000011 - momentum: 0.000000
2023-11-17 23:17:01,707 ----------------------------------------------------------------------------------------------------
2023-11-17 23:17:01,707 EPOCH 8 done: loss 0.0031 - lr: 0.000011
2023-11-17 23:17:01,847 DEV : loss 0.019760413095355034 - f1-score (micro avg)  0.8224
2023-11-17 23:17:01,862 ----------------------------------------------------------------------------------------------------
2023-11-17 23:17:02,655 epoch 9 - iter 20/206 - loss 0.00224618 - time (sec): 0.79 - samples/sec: 100.86 - lr: 0.000011 - momentum: 0.000000
2023-11-17 23:17:03,482 epoch 9 - iter 40/206 - loss 0.00189144 - time (sec): 1.62 - samples/sec: 98.80 - lr: 0.000010 - momentum: 0.000000
2023-11-17 23:17:04,353 epoch 9 - iter 60/206 - loss 0.00189817 - time (sec): 2.49 - samples/sec: 96.34 - lr: 0.000010 - momentum: 0.000000
2023-11-17 23:17:05,199 epoch 9 - iter 80/206 - loss 0.00205763 - time (sec): 3.34 - samples/sec: 95.91 - lr: 0.000009 - momentum: 0.000000
2023-11-17 23:17:06,038 epoch 9 - iter 100/206 - loss 0.00218441 - time (sec): 4.18 - samples/sec: 95.78 - lr: 0.000008 - momentum: 0.000000
2023-11-17 23:17:06,860 epoch 9 - iter 120/206 - loss 0.00220611 - time (sec): 5.00 - samples/sec: 96.04 - lr: 0.000008 - momentum: 0.000000
2023-11-17 23:17:07,689 epoch 9 - iter 140/206 - loss 0.00215295 - time (sec): 5.83 - samples/sec: 96.11 - lr: 0.000007 - momentum: 0.000000
2023-11-17 23:17:08,533 epoch 9 - iter 160/206 - loss 0.00211844 - time (sec): 6.67 - samples/sec: 95.93 - lr: 0.000007 - momentum: 0.000000
2023-11-17 23:17:09,357 epoch 9 - iter 180/206 - loss 0.00208519 - time (sec): 7.49 - samples/sec: 96.07 - lr: 0.000006 - momentum: 0.000000
2023-11-17 23:17:10,197 epoch 9 - iter 200/206 - loss 0.00205012 - time (sec): 8.33 - samples/sec: 95.99 - lr: 0.000006 - momentum: 0.000000
2023-11-17 23:17:10,440 ----------------------------------------------------------------------------------------------------
2023-11-17 23:17:10,440 EPOCH 9 done: loss 0.0020 - lr: 0.000006
2023-11-17 23:17:10,583 DEV : loss 0.015753893181681633 - f1-score (micro avg)  0.8244
2023-11-17 23:17:10,597 ----------------------------------------------------------------------------------------------------
2023-11-17 23:17:11,384 epoch 10 - iter 20/206 - loss 0.00180538 - time (sec): 0.79 - samples/sec: 101.75 - lr: 0.000005 - momentum: 0.000000
2023-11-17 23:17:12,206 epoch 10 - iter 40/206 - loss 0.00177537 - time (sec): 1.61 - samples/sec: 99.45 - lr: 0.000005 - momentum: 0.000000
2023-11-17 23:17:13,047 epoch 10 - iter 60/206 - loss 0.00202447 - time (sec): 2.45 - samples/sec: 97.99 - lr: 0.000004 - momentum: 0.000000
2023-11-17 23:17:13,917 epoch 10 - iter 80/206 - loss 0.00187494 - time (sec): 3.32 - samples/sec: 96.39 - lr: 0.000003 - momentum: 0.000000
2023-11-17 23:17:14,746 epoch 10 - iter 100/206 - loss 0.00184937 - time (sec): 4.15 - samples/sec: 96.41 - lr: 0.000003 - momentum: 0.000000
2023-11-17 23:17:15,564 epoch 10 - iter 120/206 - loss 0.00173221 - time (sec): 4.97 - samples/sec: 96.66 - lr: 0.000002 - momentum: 0.000000
2023-11-17 23:17:16,393 epoch 10 - iter 140/206 - loss 0.00175720 - time (sec): 5.80 - samples/sec: 96.62 - lr: 0.000002 - momentum: 0.000000
2023-11-17 23:17:17,232 epoch 10 - iter 160/206 - loss 0.00172661 - time (sec): 6.63 - samples/sec: 96.47 - lr: 0.000001 - momentum: 0.000000
2023-11-17 23:17:18,076 epoch 10 - iter 180/206 - loss 0.00172620 - time (sec): 7.48 - samples/sec: 96.28 - lr: 0.000001 - momentum: 0.000000
2023-11-17 23:17:18,908 epoch 10 - iter 200/206 - loss 0.00167619 - time (sec): 8.31 - samples/sec: 96.26 - lr: 0.000000 - momentum: 0.000000
2023-11-17 23:17:19,157 ----------------------------------------------------------------------------------------------------
2023-11-17 23:17:19,157 EPOCH 10 done: loss 0.0017 - lr: 0.000000
2023-11-17 23:17:19,307 DEV : loss 0.015686742961406708 - f1-score (micro avg)  0.8234
2023-11-17 23:17:19,600 ----------------------------------------------------------------------------------------------------
2023-11-17 23:17:19,600 Testing using last state of model ...
2023-11-17 23:17:20,737 AVG: mse: 0.0191 - mae: 0.1072 - pearson: 0.7718 - spearman: 0.7758
2023-11-17 23:17:20,738 ----------------------------------------------------------------------------------------------------
